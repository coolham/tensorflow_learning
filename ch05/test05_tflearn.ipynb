{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow:1.13.1\n",
      "NumPy:1.16.3\n",
      "['c:\\\\python36\\\\python36.zip', 'c:\\\\python36\\\\DLLs', 'c:\\\\python36\\\\lib', 'c:\\\\python36', '', 'c:\\\\python36\\\\lib\\\\site-packages', 'c:\\\\python36\\\\lib\\\\site-packages\\\\pip-9.0.1-py3.6.egg', 'c:\\\\python36\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\WJ\\\\.ipython', 'D:\\\\Work\\\\tensorflow_test']\n",
      "Extracting ./datasets\\mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./datasets\\mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./datasets\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./datasets\\mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9b9ddb9d1a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m model.fit(X_train, Y_train, \n\u001b[0;32m     59\u001b[0m           \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m           show_metric=True, run_id='dense_model')\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# TODO: check memory impact for large data and multiple optimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n\u001b[1;32m--> 184\u001b[1;33m                                       self.targets)\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[0mfeed_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mval_feed_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tflearn\\utils.py\u001b[0m in \u001b[0;36mfeed_dict_builder\u001b[1;34m(X, Y, net_inputs, net_targets)\u001b[0m\n\u001b[0;32m    281\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                 \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[1;31m# If a dict is provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "print('TensorFlow:{}'.format(tf.__version__))\n",
    "import numpy as np\n",
    "print('NumPy:{}'.format(np.__version__))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "current_path = os.getcwd()\n",
    "base_dir = os.path.dirname(current_path)\n",
    "\n",
    "if not base_dir in sys.path:\n",
    "    sys.path.append(base_dir)\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasetslib\n",
    "import tflearn\n",
    "\n",
    "mnist_home = os.path.join(datasetslib.datasets_root, 'mnist')\n",
    "mnist = input_data.read_data_sets(mnist_home, one_hot=True)\n",
    "\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels\n",
    "\n",
    "num_outputs = 10\n",
    "num_inputs = 784\n",
    "\n",
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "# Build deep neural network\n",
    "input_layer = tflearn.input_data(shape=[None, num_inputs])\n",
    "dense1 = tflearn.fully_connected(input_layer, num_neurons[0], activation='relu')\n",
    "dense2 = tflearn.fully_connected(dense1, num_neurons[1], activation='relu')\n",
    "softmax = tflearn.fully_connected(dense2, num_outputs, activation='softmax')\n",
    "\n",
    "optimizer = tflearn.SGD(learning_rate=learning_rate)\n",
    "net = tflearn.regression(softmax, optimizer=optimizer, \n",
    "                         metric=tflearn.metrics.Accuracy(), \n",
    "                         loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          n_epoch=n_epochs, batch_size=batch_size, \n",
    "          show_metric=True, run_id='dense_model')\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
