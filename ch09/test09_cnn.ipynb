{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-011e0cc7fe52>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting .\\mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting .\\mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting .\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-011e0cc7fe52>:72: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0000 loss = 1.248280\n",
      "Epoch: 0001 loss = 0.086571\n",
      "Epoch: 0002 loss = 0.059845\n",
      "Epoch: 0003 loss = 0.046745\n",
      "Epoch: 0004 loss = 0.038780\n",
      "Epoch: 0005 loss = 0.030985\n",
      "Epoch: 0006 loss = 0.026837\n",
      "Epoch: 0007 loss = 0.024191\n",
      "Epoch: 0008 loss = 0.021002\n",
      "Epoch: 0009 loss = 0.018627\n",
      "Model Trained.\n",
      "Accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'), one_hot=True)\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "Y_train = mnist.train.labels\n",
    "Y_test = mnist.test.labels\n",
    "\n",
    "\n",
    "n_classes = 10    # 0~9位数\n",
    "n_width = 28\n",
    "n_height = 28\n",
    "n_depth = 1\n",
    "n_inputs = n_height * n_width * n_depth  #总像素\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# 输入图像形状(n_samples, n_width, n_height, d_depth)\n",
    "x = tf.placeholder(dtype=tf.float32, name='x', shape=[None, n_inputs])\n",
    "# 输出标签\n",
    "y = tf.placeholder(dtype=tf.float32, name='y', shape=[None, n_classes])\n",
    "\n",
    "# 转换输入x为形状(n_samples, n_width, n_height, d_depth)\n",
    "x_ = tf.reshape(x, shape=[-1, n_width, n_height, n_depth])\n",
    "\n",
    "#  使用32个4x4大小的核定义第一个卷积层，从而生成32个特征图\n",
    "# 首先，定义第一个卷积层的权重和偏差，使用正态分布初始化这些参数\n",
    "layer1_w = tf.Variable(tf.random_normal(shape=[4, 4, n_depth, 32],stddev=0.1), name='l1_w')\n",
    "layer1_b = tf.Variable(tf.random_normal([32]), name='l1_b')\n",
    "\n",
    "# tf.nn.conv2d 定义卷积层\n",
    "layer1_conv = tf.nn.relu(tf.nn.conv2d(x_, layer1_w, strides=[1, 1, 1, 1], padding='SAME') + layer1_b)\n",
    "\n",
    "# tf.nn.max_pool 定义第一个池化层\n",
    "# 第一个卷积层产生32个大小为28x28x1的特征图，然后池化成32x14x14x1\n",
    "layer1_pool = tf.nn.max_pool(layer1_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 第二个卷积层用上面的数据作为输入，并生成64个特征图\n",
    "\n",
    "layer2_w = tf.Variable(tf.random_normal(shape=[4, 4, 32, 64], stddev=0.1), name='l2_w')\n",
    "layer2_b = tf.Variable(tf.random_normal([64]), name='l2_b')\n",
    "\n",
    "layer2_conv = tf.nn.relu(tf.nn.conv2d(layer1_pool, layer2_w, strides=[1,1,1,1,], padding='SAME') + layer2_b)\n",
    "\n",
    "# 第二层卷积输出的大小为64x14x14x1， 池化之后为64x7x7x1\n",
    "layer2_pool = tf.nn.max_pool(layer2_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 在输入给全连接层（它有1024个神经元）之前需要将输出结果拉伸(flat)成大小为1024的向量\n",
    "\n",
    "layer3_w = tf.Variable(tf.random_normal(shape=[64*7*7*1, 1024], stddev=0.1), name='l3_w')\n",
    "layer3_b = tf.Variable(tf.random_normal([1024]), name='l3_b')\n",
    "layer3_fc = tf.nn.relu(tf.matmul(tf.reshape(layer2_pool, [-1, 64*7*7*1]), layer3_w) + layer3_b)\n",
    "\n",
    "# 全连接层的输出已一个线性输出层(它有10个输出)相连，\n",
    "# 这一层没有使用softmax，因为损失函数会自动将softmax应用于输出\n",
    "layer4_w = tf.Variable(tf.random_normal(shape=[1024, n_classes], stddev=0.1), name='l4_w')\n",
    "layer4_b = tf.Variable(tf.random_normal([n_classes]), name='l4_b')\n",
    "layer4_out = tf.matmul(layer3_fc, layer4_w) + layer4_b\n",
    "\n",
    "# 创建第一个CNN模型，保存在变量model中\n",
    "model = layer4_out\n",
    "\n",
    "# 可用softmax_cross_entropy_with_logits定义损失函数\n",
    "# 使用AdamOptimizer作为优化器\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in range(n_batches):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {x: batch_x, y: batch_y}\n",
    "            batch_loss, _ = tfs.run([loss, optimizer], feed_dict=feed_dict)\n",
    "            total_loss += batch_loss\n",
    "        average_loss = total_loss / n_batches\n",
    "        print('Epoch: {0:04d} loss = {1:0.6f}'.format(epoch, average_loss))\n",
    "    print('Model Trained.')\n",
    "\n",
    "    predictions_check = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "    feed_dict = {x: mnist.test.images, y: mnist.test.labels}\n",
    "    print('Accuracy:', accuracy.eval(feed_dict=feed_dict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
